{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Search Analytics with DuckDB\n\nThis notebook helps you analyze your Search Analytics data using DuckDB."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# QUICK START\n\n**Just run these 2 cells to get started!**\n\n### Step 1: Set the path to your CSV file"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#################################################################\n#  ONLY SETTING: Path to your CSV file                         #\n#################################################################\n\nCSV_PATH = '../data/search_export.csv'    # <-- CHANGE THIS!\n\n#################################################################"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Step 2: Run this cell - everything else happens automatically"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== AUTOMATIC SETUP =====\n# This cell:\n# 1. Imports all required libraries\n# 2. Creates the database (.db file)\n# 3. Reads your CSV and automatically creates a table\n# 4. Normalizes column names (user_Id -> user_id, etc.)\n# 5. Converts German date formats (DD.MM.YYYY HH:MM) automatically\n# 6. Creates a session key for easy grouping\n# 7. Shows you what was imported\n\nimport duckdb\nimport pandas as pd\nimport re\nfrom pathlib import Path\n\n# Plotting optional\ntry:\n    import matplotlib.pyplot as plt\n    import matplotlib.dates as mdates\n    plt.style.use('seaborn-v0_8-whitegrid')\n    PLOTTING_AVAILABLE = True\nexcept ImportError:\n    PLOTTING_AVAILABLE = False\n\n# Pandas display options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# Create database (in same folder as CSV)\ncsv_path = Path(CSV_PATH)\ndb_path = csv_path.parent / 'searchanalytics.db'\n\n# Establish connection\ncon = duckdb.connect(str(db_path))\n\n# Helper functions\ndef query(sql):\n    \"\"\"Execute SQL and return DataFrame\"\"\"\n    return con.execute(sql).df()\n\ndef execute(sql):\n    \"\"\"Execute SQL without return\"\"\"\n    con.execute(sql)\n\n# Create table from CSV\nprint(\"=\"*60)\nprint(\"AUTOMATIC IMPORT\")\nprint(\"=\"*60)\n\n# Drop table if exists, then recreate\nexecute(\"DROP TABLE IF EXISTS searches\")\n\n# Read CSV\nexecute(f\"\"\"\n    CREATE TABLE searches AS\n    SELECT * FROM read_csv('{CSV_PATH}', auto_detect=true)\n\"\"\")\n\n# Normalize column names (user_Id -> user_id, session_Id -> session_id)\nprint(\"\\nNormalizing column names...\")\nschema = query(\"DESCRIBE searches\")\ncol_names = schema['column_name'].tolist()\n\nrename_map = {\n    'user_Id': 'user_id',\n    'session_Id': 'session_id'\n}\n\nrenamed_cols = []\nfor old_name, new_name in rename_map.items():\n    if old_name in col_names:\n        execute(f\"ALTER TABLE searches RENAME COLUMN {old_name} TO {new_name}\")\n        renamed_cols.append(f\"{old_name} → {new_name}\")\n\nif renamed_cols:\n    print(f\"  Renamed: {', '.join(renamed_cols)}\")\nelse:\n    print(\"  No renaming needed\")\n\n# Automatically convert German date formats (DD.MM.YYYY or DD.MM.YYYY HH:MM)\nprint(\"\\nChecking for German date formats...\")\nschema = query(\"DESCRIBE searches\")\nvarchar_cols = schema[schema['column_type'] == 'VARCHAR']['column_name'].tolist()\n\nconverted_cols = []\nfor col in varchar_cols:\n    # Check first non-null value\n    sample = query(f\"SELECT {col} FROM searches WHERE {col} IS NOT NULL LIMIT 1\")\n    if len(sample) > 0:\n        val = str(sample.iloc[0, 0])\n        # Detect German date: DD.MM.YYYY or DD.MM.YYYY HH:MM\n        if re.match(r'^\\d{2}\\.\\d{2}\\.\\d{4}', val):\n            try:\n                # Determine format\n                if re.match(r'^\\d{2}\\.\\d{2}\\.\\d{4} \\d{2}:\\d{2}(:\\d{2})?$', val):\n                    # With time\n                    if val.count(':') == 2:\n                        fmt = '%d.%m.%Y %H:%M:%S'\n                    else:\n                        fmt = '%d.%m.%Y %H:%M'\n                else:\n                    # Date only\n                    fmt = '%d.%m.%Y'\n                \n                # Convert\n                execute(f\"ALTER TABLE searches ADD COLUMN {col}_temp TIMESTAMP\")\n                execute(f\"UPDATE searches SET {col}_temp = strptime({col}, '{fmt}')\")\n                execute(f\"ALTER TABLE searches DROP COLUMN {col}\")\n                execute(f\"ALTER TABLE searches RENAME COLUMN {col}_temp TO {col}\")\n                converted_cols.append(col)\n            except Exception as e:\n                print(f\"  Warning: Could not convert {col}: {e}\")\n\nif converted_cols:\n    print(f\"  Converted: {', '.join(converted_cols)}\")\nelse:\n    print(\"  No German date formats found\")\n\n# Create session key (if user_id and session_id exist)\nprint(\"\\nChecking for session fields...\")\nschema = query(\"DESCRIBE searches\")\ncol_names = schema['column_name'].tolist()\n\nhas_user_id = 'user_id' in col_names\nhas_session_id = 'session_id' in col_names\nhas_timestamp = 'timestamp' in col_names\n\nif has_user_id and has_session_id and has_timestamp:\n    execute(\"\"\"\n        ALTER TABLE searches ADD COLUMN session_date DATE;\n    \"\"\")\n    execute(\"\"\"\n        UPDATE searches SET session_date = DATE_TRUNC('day', timestamp)::DATE;\n    \"\"\")\n    execute(\"\"\"\n        ALTER TABLE searches ADD COLUMN session_key VARCHAR;\n    \"\"\")\n    execute(\"\"\"\n        UPDATE searches SET session_key = \n            COALESCE(CAST(session_date AS VARCHAR), '') || '_' || \n            COALESCE(user_id, '') || '_' || \n            COALESCE(session_id, '');\n    \"\"\")\n    print(\"  session_date created (day from timestamp)\")\n    print(\"  session_key created (session_date + user_id + session_id)\")\n    print(\"  → Group with: GROUP BY session_key\")\nelif has_user_id and has_session_id:\n    execute(\"\"\"\n        ALTER TABLE searches ADD COLUMN session_key VARCHAR;\n    \"\"\")\n    execute(\"\"\"\n        UPDATE searches SET session_key = \n            COALESCE(user_id, '') || '_' || \n            COALESCE(session_id, '');\n    \"\"\")\n    print(\"  session_key created (user_id + session_id)\")\n    print(\"  Note: No timestamp found, session_date not created\")\nelse:\n    missing = []\n    if not has_user_id: missing.append('user_id')\n    if not has_session_id: missing.append('session_id')\n    print(f\"  Missing columns: {', '.join(missing)}\")\n    print(\"  → session_key not created\")\n\n# What was imported?\nrow_count = query(\"SELECT COUNT(*) as n FROM searches\")['n'][0]\nprint(f\"\\n CSV file: {csv_path.name}\")\nprint(f\" Database: {db_path.name}\")\nprint(f\" Imported: {row_count:,} rows\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"DETECTED COLUMNS\")\nprint(\"=\"*60)\nschema = query(\"DESCRIBE searches\")\nfor _, row in schema.iterrows():\n    print(f\"  {row['column_name']:30} {row['column_type']}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FIRST 5 ROWS\")\nprint(\"=\"*60)\ndisplay(query(\"SELECT * FROM searches LIMIT 5\"))\n\nprint(\"\\n Setup complete! You can now run the analysis cells below.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# ANALYSES\n\nFrom here you can run the cells that interest you.\n\n**Important:** If your columns have different names, adjust them in the queries!\nTypical column variants:\n- Timestamp: `timestamp`, `date`, `datetime`, `created_at`\n- Search term: `search_query`, `query`, `search_term`, `keyword`\n- Results: `results_count`, `result_count`, `hits`, `total_results`\n- Response time: `response_time`, `duration`, `latency_ms`\n\n---\n## Basic Statistics"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Overview: What do we have?\nquery(\"DESCRIBE searches\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# First and last entries\nquery(\"\"\"\n    SELECT\n        COUNT(*) as total_rows,\n        MIN(timestamp) as first_entry,\n        MAX(timestamp) as last_entry\n    FROM searches\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# View sample data\nquery(\"SELECT * FROM searches LIMIT 20\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Time Distribution"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Entries per day\n# NOTE: Replace 'timestamp' with your date column if needed\n\nquery(\"\"\"\n    SELECT\n        DATE_TRUNC('day', timestamp)::DATE as date,\n        COUNT(*) as count\n    FROM searches\n    GROUP BY 1\n    ORDER BY 1 DESC\n    LIMIT 30\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Distribution by hour\nquery(\"\"\"\n    SELECT\n        EXTRACT(HOUR FROM timestamp) as hour,\n        COUNT(*) as count,\n        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 2) as percent\n    FROM searches\n    GROUP BY 1\n    ORDER BY 1\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Distribution by weekday\nquery(\"\"\"\n    SELECT\n        DAYNAME(timestamp) as weekday,\n        DAYOFWEEK(timestamp) as day_nr,\n        COUNT(*) as count\n    FROM searches\n    GROUP BY 1, 2\n    ORDER BY 2\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Session Analyses\n\nAnalyses based on user sessions (grouped by session_key = day + user_id + session_id)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Session overview: How many sessions, how many searches per session?\nquery(\"\"\"\n    SELECT\n        COUNT(DISTINCT session_key) as total_sessions,\n        COUNT(*) as total_searches,\n        ROUND(COUNT(*) * 1.0 / COUNT(DISTINCT session_key), 1) as avg_searches_per_session,\n        COUNT(DISTINCT user_id) as unique_users\n    FROM searches\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Distribution: Number of searches per session\nquery(\"\"\"\n    SELECT\n        searches_in_session,\n        COUNT(*) as session_count,\n        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 1) as percent\n    FROM (\n        SELECT session_key, COUNT(*) as searches_in_session\n        FROM searches\n        GROUP BY session_key\n    )\n    GROUP BY 1\n    ORDER BY 1\n    LIMIT 20\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Sessions with most searches (power users / problems?)\nquery(\"\"\"\n    SELECT\n        session_key,\n        session_date,\n        user_id,\n        session_id,\n        COUNT(*) as search_count,\n        MIN(timestamp) as first_search,\n        MAX(timestamp) as last_search,\n        DATEDIFF('minute', MIN(timestamp), MAX(timestamp)) as duration_minutes\n    FROM searches\n    GROUP BY session_key, session_date, user_id, session_id\n    ORDER BY search_count DESC\n    LIMIT 20\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# User activity: How many sessions per user?\nquery(\"\"\"\n    SELECT\n        user_id,\n        COUNT(DISTINCT session_key) as session_count,\n        COUNT(*) as total_searches,\n        ROUND(COUNT(*) * 1.0 / COUNT(DISTINCT session_key), 1) as searches_per_session,\n        MIN(session_date) as first_session,\n        MAX(session_date) as last_session\n    FROM searches\n    GROUP BY user_id\n    ORDER BY session_count DESC\n    LIMIT 20\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Session timeline: Show all activities for a specific session\n# Replace session_key with a value from the query above\n\nSESSION_KEY = 'ENTER_SESSION_KEY_HERE'  # <-- Change this\n\nquery(f\"\"\"\n    SELECT *\n    FROM searches\n    WHERE session_key = '{SESSION_KEY}'\n    ORDER BY timestamp\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Sessions per day\nquery(\"\"\"\n    SELECT\n        session_date as date,\n        COUNT(DISTINCT session_key) as sessions,\n        COUNT(DISTINCT user_id) as unique_users,\n        COUNT(*) as total_searches,\n        ROUND(COUNT(*) * 1.0 / COUNT(DISTINCT session_key), 1) as searches_per_session\n    FROM searches\n    GROUP BY 1\n    ORDER BY 1 DESC\n    LIMIT 30\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Search Journey Analysis\n\nAnalyzes the complete search flow per session: Search → Results → Click?\n\n**Event types:**\n- `SEARCH_TRIGGERED` / `SEARCH_STARTED` - User starts search\n- `SEARCH_RESULT_COUNT` - Results are displayed\n- `SEARCH_TAB_CLICK`, `SEARCH_ALL_TAB_PAGE_CLICK`, `SEARCH_NEWS_TAB_PAGE_CLICK`, `SEARCH_GOTO_TAB_PAGE_CLICK` - User clicks on result\n\n**Success = Search leads to click**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Overview: What event types do we have?\nquery(\"\"\"\n    SELECT \n        name as event_type,\n        COUNT(*) as count,\n        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 1) as percent\n    FROM searches\n    GROUP BY 1\n    ORDER BY 2 DESC\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Search Funnel: How many searches → results → clicks?\nquery(\"\"\"\n    SELECT\n        COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED') THEN session_key END) as sessions_with_search,\n        COUNT(DISTINCT CASE WHEN name = 'SEARCH_RESULT_COUNT' THEN session_key END) as sessions_with_results,\n        COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK') THEN session_key END) as sessions_with_click,\n        ROUND(100.0 * COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK') THEN session_key END) \n            / NULLIF(COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED') THEN session_key END), 0), 1) as click_through_rate_pct\n    FROM searches\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Null-result searches: Which search terms return 0 results?\nquery(\"\"\"\n    SELECT \n        COALESCE(CP_searchQuery, searchQuery, query) as search_term,\n        COUNT(*) as count,\n        AVG(CAST(CP_totalResultCount AS INTEGER)) as avg_results,\n        SUM(CASE WHEN CAST(CP_totalResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END) as null_result_count,\n        ROUND(100.0 * SUM(CASE WHEN CAST(CP_totalResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END) / COUNT(*), 1) as null_rate_pct\n    FROM searches\n    WHERE name = 'SEARCH_RESULT_COUNT'\n    GROUP BY 1\n    HAVING COUNT(*) >= 3\n    ORDER BY null_result_count DESC\n    LIMIT 30\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Top search terms with success rate (click after search)\nquery(\"\"\"\n    WITH searches_with_query AS (\n        SELECT \n            session_key,\n            COALESCE(CP_searchQuery, searchQuery, query) as search_term,\n            name,\n            timestamp\n        FROM searches\n        WHERE COALESCE(CP_searchQuery, searchQuery, query) IS NOT NULL\n    ),\n    search_events AS (\n        SELECT DISTINCT session_key, search_term\n        FROM searches_with_query \n        WHERE name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED', 'SEARCH_RESULT_COUNT')\n    ),\n    click_events AS (\n        SELECT DISTINCT session_key\n        FROM searches_with_query\n        WHERE name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK')\n    )\n    SELECT \n        s.search_term,\n        COUNT(*) as search_count,\n        SUM(CASE WHEN c.session_key IS NOT NULL THEN 1 ELSE 0 END) as with_click,\n        ROUND(100.0 * SUM(CASE WHEN c.session_key IS NOT NULL THEN 1 ELSE 0 END) / COUNT(*), 1) as success_rate_pct\n    FROM search_events s\n    LEFT JOIN click_events c ON s.session_key = c.session_key\n    GROUP BY 1\n    HAVING COUNT(*) >= 5\n    ORDER BY search_count DESC\n    LIMIT 30\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Problematic searches: Many results but no clicks (user doesn't find what they need)\nquery(\"\"\"\n    WITH search_results AS (\n        SELECT \n            session_key,\n            COALESCE(CP_searchQuery, searchQuery, query) as search_term,\n            CAST(CP_totalResultCount AS INTEGER) as total_results\n        FROM searches\n        WHERE name = 'SEARCH_RESULT_COUNT'\n          AND CAST(CP_totalResultCount AS INTEGER) > 0\n    ),\n    click_events AS (\n        SELECT DISTINCT session_key\n        FROM searches\n        WHERE name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK')\n    )\n    SELECT \n        sr.search_term,\n        COUNT(*) as search_count,\n        ROUND(AVG(sr.total_results), 0) as avg_results,\n        SUM(CASE WHEN c.session_key IS NULL THEN 1 ELSE 0 END) as without_click,\n        ROUND(100.0 * SUM(CASE WHEN c.session_key IS NULL THEN 1 ELSE 0 END) / COUNT(*), 1) as abandon_rate_pct\n    FROM search_results sr\n    LEFT JOIN click_events c ON sr.session_key = c.session_key\n    GROUP BY 1\n    HAVING COUNT(*) >= 5 AND SUM(CASE WHEN c.session_key IS NULL THEN 1 ELSE 0 END) > 0\n    ORDER BY without_click DESC\n    LIMIT 30\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Search reformulations: Sessions with multiple searches (user needs to adjust query)\nquery(\"\"\"\n    WITH session_searches AS (\n        SELECT \n            session_key,\n            COUNT(DISTINCT COALESCE(CP_searchQuery, searchQuery, query)) as unique_queries,\n            COUNT(*) as total_search_events\n        FROM searches\n        WHERE name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED')\n          AND COALESCE(CP_searchQuery, searchQuery, query) IS NOT NULL\n        GROUP BY 1\n        HAVING COUNT(DISTINCT COALESCE(CP_searchQuery, searchQuery, query)) > 1\n    )\n    SELECT \n        unique_queries as different_search_count,\n        COUNT(*) as sessions,\n        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 1) as percent\n    FROM session_searches\n    GROUP BY 1\n    ORDER BY 1\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Complete journey of a session\n# Choose a session_key from above\n\nSESSION_KEY = 'ENTER_SESSION_KEY_HERE'  # <-- Change this\n\nquery(f\"\"\"\n    SELECT \n        timestamp,\n        name as event,\n        COALESCE(CP_searchQuery, searchQuery, query) as search_term,\n        CP_totalResultCount as results,\n        CP_peopleResultCount as people,\n        CP_newsResultCount as news,\n        CP_gotoResultCount as goto\n    FROM searches\n    WHERE session_key = '{SESSION_KEY}'\n    ORDER BY timestamp\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Result distribution by category: Where do results come from?\nquery(\"\"\"\n    SELECT\n        'Total' as category,\n        COUNT(*) as searches_with_result,\n        ROUND(AVG(CAST(CP_totalResultCount AS FLOAT)), 1) as avg_count,\n        SUM(CASE WHEN CAST(CP_totalResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END) as null_results\n    FROM searches WHERE name = 'SEARCH_RESULT_COUNT'\n    \n    UNION ALL\n    \n    SELECT 'People', COUNT(*), ROUND(AVG(CAST(CP_peopleResultCount AS FLOAT)), 1),\n        SUM(CASE WHEN CAST(CP_peopleResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n    FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_peopleResultCount IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT 'News', COUNT(*), ROUND(AVG(CAST(CP_newsResultCount AS FLOAT)), 1),\n        SUM(CASE WHEN CAST(CP_newsResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n    FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_newsResultCount IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT 'Intranet News', COUNT(*), ROUND(AVG(CAST(CP_intranetNewsResultCount AS FLOAT)), 1),\n        SUM(CASE WHEN CAST(CP_intranetNewsResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n    FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_intranetNewsResultCount IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT 'GoTo', COUNT(*), ROUND(AVG(CAST(CP_gotoResultCount AS FLOAT)), 1),\n        SUM(CASE WHEN CAST(CP_gotoResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n    FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_gotoResultCount IS NOT NULL\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Click distribution: Which result categories are clicked?\nquery(\"\"\"\n    SELECT \n        name as click_type,\n        COUNT(*) as count,\n        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 1) as percent\n    FROM searches\n    WHERE name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK')\n    GROUP BY 1\n    ORDER BY 2 DESC\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Top Values (adjustable for any column)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Top 20 most frequent values of a column\n# NOTE: Replace 'search_query' with the column you're interested in\n\nCOLUMN = 'search_query'  # <-- Change this\n\nquery(f\"\"\"\n    SELECT\n        {COLUMN},\n        COUNT(*) as count,\n        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 2) as percent\n    FROM searches\n    WHERE {COLUMN} IS NOT NULL\n    GROUP BY 1\n    ORDER BY 2 DESC\n    LIMIT 20\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Null-Result Analysis\n\nIf you have a column with result count (e.g. `results_count`)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Overall null rate\n# NOTE: Replace 'results_count' with your column\n\nquery(\"\"\"\n    SELECT\n        COUNT(*) as total_searches,\n        SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) as null_results,\n        ROUND(100.0 * SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) / COUNT(*), 2) as null_rate_pct\n    FROM searches\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Search terms with most null results\nquery(\"\"\"\n    SELECT\n        search_query,\n        COUNT(*) as count,\n        SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) as null_results,\n        ROUND(100.0 * SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) / COUNT(*), 1) as null_rate_pct\n    FROM searches\n    WHERE search_query IS NOT NULL\n    GROUP BY 1\n    HAVING COUNT(*) >= 5  -- At least 5 searches\n    ORDER BY null_results DESC\n    LIMIT 20\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Null rate per day\nquery(\"\"\"\n    SELECT\n        DATE_TRUNC('day', timestamp)::DATE as date,\n        COUNT(*) as total,\n        SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) as null_results,\n        ROUND(100.0 * SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) / COUNT(*), 2) as null_rate_pct\n    FROM searches\n    GROUP BY 1\n    ORDER BY 1 DESC\n    LIMIT 30\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Export Search Journey Analysis (Excel)\n\nExports all journey analyses to an Excel file with separate tabs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Search Journey Analysis → Excel Export\nfrom datetime import datetime\nfrom pathlib import Path\n\n# Requires openpyxl: conda install openpyxl\ntry:\n    from openpyxl import Workbook\n    from openpyxl.worksheet.table import Table, TableStyleInfo\n    from openpyxl.utils.dataframe import dataframe_to_rows\n    from openpyxl.utils import get_column_letter\nexcept ImportError:\n    print(\"openpyxl not installed. Run: conda install openpyxl\")\n    raise\n\n# Define all queries\njourney_queries = {\n    \"Event-Overview\": \"\"\"\n        SELECT \n            name as Event_Type,\n            COUNT(*) as Count,\n            ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 1) as Percent\n        FROM searches\n        GROUP BY 1\n        ORDER BY 2 DESC\n    \"\"\",\n    \n    \"Search-Funnel\": \"\"\"\n        SELECT\n            COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED') THEN session_key END) as Sessions_With_Search,\n            COUNT(DISTINCT CASE WHEN name = 'SEARCH_RESULT_COUNT' THEN session_key END) as Sessions_With_Results,\n            COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK') THEN session_key END) as Sessions_With_Click,\n            ROUND(100.0 * COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK') THEN session_key END) \n                / NULLIF(COUNT(DISTINCT CASE WHEN name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED') THEN session_key END), 0), 1) as Click_Through_Rate_Pct\n        FROM searches\n    \"\"\",\n    \n    \"Null-Results\": \"\"\"\n        SELECT \n            COALESCE(CP_searchQuery, searchQuery, query) as Search_Term,\n            COUNT(*) as Count,\n            ROUND(AVG(CAST(CP_totalResultCount AS FLOAT)), 1) as Avg_Results,\n            SUM(CASE WHEN CAST(CP_totalResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END) as Null_Result_Count,\n            ROUND(100.0 * SUM(CASE WHEN CAST(CP_totalResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END) / COUNT(*), 1) as Null_Rate_Pct\n        FROM searches\n        WHERE name = 'SEARCH_RESULT_COUNT'\n        GROUP BY 1\n        HAVING COUNT(*) >= 3\n        ORDER BY Null_Result_Count DESC\n        LIMIT 100\n    \"\"\",\n    \n    \"Success-Rate\": \"\"\"\n        WITH searches_with_query AS (\n            SELECT \n                session_key,\n                COALESCE(CP_searchQuery, searchQuery, query) as search_term,\n                name\n            FROM searches\n            WHERE COALESCE(CP_searchQuery, searchQuery, query) IS NOT NULL\n        ),\n        search_events AS (\n            SELECT DISTINCT session_key, search_term\n            FROM searches_with_query \n            WHERE name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED', 'SEARCH_RESULT_COUNT')\n        ),\n        click_events AS (\n            SELECT DISTINCT session_key\n            FROM searches_with_query\n            WHERE name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK')\n        )\n        SELECT \n            s.search_term as Search_Term,\n            COUNT(*) as Search_Count,\n            SUM(CASE WHEN c.session_key IS NOT NULL THEN 1 ELSE 0 END) as With_Click,\n            ROUND(100.0 * SUM(CASE WHEN c.session_key IS NOT NULL THEN 1 ELSE 0 END) / COUNT(*), 1) as Success_Rate_Pct\n        FROM search_events s\n        LEFT JOIN click_events c ON s.session_key = c.session_key\n        GROUP BY 1\n        HAVING COUNT(*) >= 5\n        ORDER BY Search_Count DESC\n        LIMIT 100\n    \"\"\",\n    \n    \"Abandoned-Searches\": \"\"\"\n        WITH search_results AS (\n            SELECT \n                session_key,\n                COALESCE(CP_searchQuery, searchQuery, query) as search_term,\n                CAST(CP_totalResultCount AS INTEGER) as total_results\n            FROM searches\n            WHERE name = 'SEARCH_RESULT_COUNT'\n              AND CAST(CP_totalResultCount AS INTEGER) > 0\n        ),\n        click_events AS (\n            SELECT DISTINCT session_key\n            FROM searches\n            WHERE name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK')\n        )\n        SELECT \n            sr.search_term as Search_Term,\n            COUNT(*) as Search_Count,\n            ROUND(AVG(sr.total_results), 0) as Avg_Results,\n            SUM(CASE WHEN c.session_key IS NULL THEN 1 ELSE 0 END) as Without_Click,\n            ROUND(100.0 * SUM(CASE WHEN c.session_key IS NULL THEN 1 ELSE 0 END) / COUNT(*), 1) as Abandon_Rate_Pct\n        FROM search_results sr\n        LEFT JOIN click_events c ON sr.session_key = c.session_key\n        GROUP BY 1\n        HAVING COUNT(*) >= 5 AND SUM(CASE WHEN c.session_key IS NULL THEN 1 ELSE 0 END) > 0\n        ORDER BY Without_Click DESC\n        LIMIT 100\n    \"\"\",\n    \n    \"Reformulations\": \"\"\"\n        WITH session_searches AS (\n            SELECT \n                session_key,\n                COUNT(DISTINCT COALESCE(CP_searchQuery, searchQuery, query)) as unique_queries\n            FROM searches\n            WHERE name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED')\n              AND COALESCE(CP_searchQuery, searchQuery, query) IS NOT NULL\n            GROUP BY 1\n            HAVING COUNT(DISTINCT COALESCE(CP_searchQuery, searchQuery, query)) > 1\n        )\n        SELECT \n            unique_queries as Different_Search_Count,\n            COUNT(*) as Sessions,\n            ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 1) as Percent\n        FROM session_searches\n        GROUP BY 1\n        ORDER BY 1\n    \"\"\",\n    \n    \"Result-Categories\": \"\"\"\n        SELECT\n            'Total' as Category,\n            COUNT(*) as Searches,\n            ROUND(AVG(CAST(CP_totalResultCount AS FLOAT)), 1) as Avg_Count,\n            SUM(CASE WHEN CAST(CP_totalResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END) as Null_Results\n        FROM searches WHERE name = 'SEARCH_RESULT_COUNT'\n        \n        UNION ALL\n        \n        SELECT 'People', COUNT(*), ROUND(AVG(CAST(CP_peopleResultCount AS FLOAT)), 1),\n            SUM(CASE WHEN CAST(CP_peopleResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n        FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_peopleResultCount IS NOT NULL\n        \n        UNION ALL\n        \n        SELECT 'News', COUNT(*), ROUND(AVG(CAST(CP_newsResultCount AS FLOAT)), 1),\n            SUM(CASE WHEN CAST(CP_newsResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n        FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_newsResultCount IS NOT NULL\n        \n        UNION ALL\n        \n        SELECT 'Intranet News', COUNT(*), ROUND(AVG(CAST(CP_intranetNewsResultCount AS FLOAT)), 1),\n            SUM(CASE WHEN CAST(CP_intranetNewsResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n        FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_intranetNewsResultCount IS NOT NULL\n        \n        UNION ALL\n        \n        SELECT 'GoTo', COUNT(*), ROUND(AVG(CAST(CP_gotoResultCount AS FLOAT)), 1),\n            SUM(CASE WHEN CAST(CP_gotoResultCount AS INTEGER) = 0 THEN 1 ELSE 0 END)\n        FROM searches WHERE name = 'SEARCH_RESULT_COUNT' AND CP_gotoResultCount IS NOT NULL\n    \"\"\",\n    \n    \"Click-Distribution\": \"\"\"\n        SELECT \n            name as Click_Type,\n            COUNT(*) as Count,\n            ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 1) as Percent\n        FROM searches\n        WHERE name IN ('SEARCH_TAB_CLICK', 'SEARCH_ALL_TAB_PAGE_CLICK', 'SEARCH_NEWS_TAB_PAGE_CLICK', 'SEARCH_GOTO_TAB_PAGE_CLICK')\n        GROUP BY 1\n        ORDER BY 2 DESC\n    \"\"\",\n    \n    \"Top-Search-Terms\": \"\"\"\n        SELECT \n            COALESCE(CP_searchQuery, searchQuery, query) as Search_Term,\n            COUNT(*) as Count,\n            ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 2) as Percent\n        FROM searches\n        WHERE COALESCE(CP_searchQuery, searchQuery, query) IS NOT NULL\n          AND name IN ('SEARCH_TRIGGERED', 'SEARCH_STARTED', 'SEARCH_RESULT_COUNT')\n        GROUP BY 1\n        ORDER BY 2 DESC\n        LIMIT 100\n    \"\"\"\n}\n\n# Create Excel file\noutput_file = f'../output/search_journey_analysis_{datetime.now().strftime(\"%Y%m%d\")}.xlsx'\noutput_path = Path(output_file)\noutput_path.parent.mkdir(parents=True, exist_ok=True)\n\nwb = Workbook()\nwb.remove(wb.active)  # Remove default sheet\n\ntable_style = TableStyleInfo(\n    name=\"TableStyleMedium9\",\n    showFirstColumn=False,\n    showLastColumn=False,\n    showRowStripes=True,\n    showColumnStripes=False\n)\n\nfor sheet_name, sql in journey_queries.items():\n    # Execute query\n    df = query(sql)\n    \n    # Create sheet (max 31 characters for sheet name)\n    ws = wb.create_sheet(title=sheet_name[:31])\n    \n    # Write DataFrame to sheet\n    for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n        for c_idx, value in enumerate(row, 1):\n            ws.cell(row=r_idx, column=c_idx, value=value)\n    \n    # Auto-adjust column width\n    for col_idx, column in enumerate(df.columns, 1):\n        max_length = max(\n            len(str(column)),\n            df[column].astype(str).str.len().max() if len(df) > 0 else 0\n        )\n        ws.column_dimensions[get_column_letter(col_idx)].width = min(max_length + 2, 50)\n    \n    # Format as table\n    if len(df) > 0:\n        table_ref = f\"A1:{get_column_letter(len(df.columns))}{len(df) + 1}\"\n        table = Table(displayName=sheet_name.replace(\"-\", \"_\").replace(\" \", \"_\"), ref=table_ref)\n        table.tableStyleInfo = table_style\n        ws.add_table(table)\n\n# Save\nwb.save(output_file)\n\nprint(f\"Excel exported: {output_file}\")\nprint(f\"\\nIncluded tabs:\")\nfor name in journey_queries.keys():\n    print(f\"  • {name}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Performance Metrics\n\nIf you have a column with response time (e.g. `response_time`)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Response time statistics\n# NOTE: Replace 'response_time' with your column\n\nquery(\"\"\"\n    SELECT\n        COUNT(*) as total,\n        ROUND(AVG(response_time), 2) as avg_ms,\n        ROUND(MEDIAN(response_time), 2) as median_ms,\n        ROUND(PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY response_time), 2) as p90_ms,\n        ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY response_time), 2) as p95_ms,\n        ROUND(PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY response_time), 2) as p99_ms,\n        ROUND(MAX(response_time), 2) as max_ms\n    FROM searches\n    WHERE response_time IS NOT NULL\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Visualizations\n\nIf Matplotlib is installed (`conda install matplotlib`)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if PLOTTING_AVAILABLE:\n    # Entries per day\n    daily = query(\"\"\"\n        SELECT\n            DATE_TRUNC('day', timestamp)::DATE as date,\n            COUNT(*) as count\n        FROM searches\n        GROUP BY 1\n        ORDER BY 1\n    \"\"\")\n    \n    fig, ax = plt.subplots(figsize=(14, 5))\n    ax.plot(daily['date'], daily['count'], linewidth=2, color='steelblue')\n    ax.fill_between(daily['date'], daily['count'], alpha=0.3, color='steelblue')\n    ax.set_title('Entries per Day', fontsize=14, fontweight='bold')\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Count')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Matplotlib not installed. Run: conda install matplotlib\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if PLOTTING_AVAILABLE:\n    # Distribution by hour\n    hourly = query(\"\"\"\n        SELECT\n            EXTRACT(HOUR FROM timestamp)::INT as hour,\n            COUNT(*) as count\n        FROM searches\n        GROUP BY 1\n        ORDER BY 1\n    \"\"\")\n    \n    fig, ax = plt.subplots(figsize=(12, 5))\n    ax.bar(hourly['hour'], hourly['count'], color='steelblue')\n    ax.set_title('Distribution by Time of Day', fontsize=14, fontweight='bold')\n    ax.set_xlabel('Hour')\n    ax.set_ylabel('Count')\n    ax.set_xticks(range(0, 24))\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if PLOTTING_AVAILABLE:\n    # Top 10 values\n    COLUMN = 'search_query'  # <-- Change this\n    \n    top = query(f\"\"\"\n        SELECT {COLUMN} as value, COUNT(*) as count\n        FROM searches\n        WHERE {COLUMN} IS NOT NULL AND {COLUMN} != ''\n        GROUP BY 1\n        ORDER BY 2 DESC\n        LIMIT 10\n    \"\"\")\n    \n    fig, ax = plt.subplots(figsize=(10, 6))\n    y_pos = range(len(top))\n    ax.barh(y_pos, top['count'], color='steelblue')\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(top['value'])\n    ax.invert_yaxis()\n    ax.set_title(f'Top 10: {COLUMN}', fontsize=14, fontweight='bold')\n    ax.set_xlabel('Count')\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Custom Queries\n\nWrite your own SQL queries here:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Your custom query here:\nquery(\"\"\"\n    SELECT *\n    FROM searches\n    LIMIT 10\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Another query:\nquery(\"\"\"\n    SELECT *\n    FROM searches\n    LIMIT 10\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Export for Power BI\n\nParquet files are ideal for Power BI: smaller, faster, data types preserved."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Raw data export (all data)\nfrom datetime import datetime\nfrom pathlib import Path\nimport os\n\n# Fixed filename for Power BI folder refresh\noutput_file = '../output/searches_raw.parquet'\noutput_path = Path(output_file)\n\n# Delete old file if exists (avoids corrupt files)\nif output_path.exists():\n    output_path.unlink()\n\n# Export\nexecute(f\"COPY searches TO '{output_file}' (FORMAT PARQUET)\")\n\n# Verify file is valid\ntry:\n    test_read = query(f\"SELECT COUNT(*) as n FROM read_parquet('{output_file}')\")\n    row_count = test_read['n'][0]\n    size_mb = os.path.getsize(output_file) / (1024 * 1024)\n    \n    print(f\"Exported: {output_file}\")\n    print(f\"Rows:     {row_count:,}\")\n    print(f\"Size:     {size_mb:.1f} MB\")\n    print(f\"Status:   Parquet file validated\")\n    print(f\"\\nIn Power BI: Get Data → Folder → {Path(output_file).parent}\")\nexcept Exception as e:\n    print(f\"ERROR: Parquet file is invalid: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aggregated daily data (for long periods / trend dashboards)\noutput_file = '../output/searches_daily.parquet'\noutput_path = Path(output_file)\n\n# Delete old file if exists\nif output_path.exists():\n    output_path.unlink()\n\nexecute(f\"\"\"\n    COPY (\n        SELECT \n            DATE_TRUNC('day', timestamp)::DATE as date,\n            COUNT(*) as total_searches,\n            COUNT(DISTINCT search_query) as unique_queries,\n            SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) as null_results,\n            ROUND(100.0 * SUM(CASE WHEN results_count = 0 THEN 1 ELSE 0 END) / COUNT(*), 2) as null_rate_pct\n        FROM searches\n        GROUP BY 1\n        ORDER BY 1\n    ) TO '{output_file}' (FORMAT PARQUET)\n\"\"\")\n\n# Verify\ntry:\n    test_read = query(f\"SELECT COUNT(*) as n FROM read_parquet('{output_file}')\")\n    days = test_read['n'][0]\n    size_mb = os.path.getsize(output_file) / (1024 * 1024)\n    \n    print(f\"Exported: {output_file}\")\n    print(f\"Days:     {days}\")\n    print(f\"Size:     {size_mb:.2f} MB\")\n    print(f\"Status:   Parquet file validated\")\nexcept Exception as e:\n    print(f\"ERROR: Parquet file is invalid: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Add New Data\n\nIf you want to import additional CSV files later:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Append new CSV to existing table\n# NEW_CSV = '../data/new_data.csv'\n\n# execute(f\"\"\"\n#     INSERT INTO searches\n#     SELECT * FROM read_csv('{NEW_CSV}', auto_detect=true)\n# \"\"\")\n\n# print(f\"New data added. Total: {query('SELECT COUNT(*) FROM searches')['count_star()'][0]:,} rows\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Cleanup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Close connection (at end of session)\ncon.close()\nprint(\"Connection closed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Notes\n\n**My columns:**\n- ...\n\n**Findings:**\n- ...\n\n**Open questions:**\n- ..."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}